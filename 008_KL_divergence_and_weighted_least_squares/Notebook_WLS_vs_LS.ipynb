{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1ff3a8-0005-4793-b6ff-127bd40fbbf7",
   "metadata": {},
   "source": [
    "## Comparison between the Least Square and the Weighted Least Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6cf50-ea61-420c-ae83-31aa30e20523",
   "metadata": {},
   "source": [
    "As we know, the data in computed tomography is affected by Poisson Noise due to the electromagnetic nature of X-rays. The Poisson distribution can be easily approximated by a Gaussian when the mean is high, but it differs from it when the mean is lower. This is the case of Low Dose CT, where the number of photon that reach the detector pixels are less than standard CT. \n",
    "Here we briefly summarize the acquisition model:\n",
    "$$I = I_{0} e^{-Ax}$$\n",
    "where $I$ is the intensity data collected by the detector, $I_{0}$ is the incoming souce intensity, $A$ is the projection operator of Computed Tomography and $x$ is the object (attenuation coefficients) that we want to reconstruct. When adding the Poisson Noise we have:\n",
    "$$ B = Poisson (I). $$ \n",
    "Most of the standard CT reconstruction strategies work by solving the linear sistem\n",
    "$$ Y = Ax$$\n",
    "where $Y = -\\log (\\frac{B}{I_{0}})$ is the sinogram data (obtained after taking the negative logarithm of $\\frac{B}{I_{0}}$). In particular, the least square problem relies on finding $x$ by solving the following minimization problem:\n",
    "$$ \\min_{x} \\mathcal{F}(x) := \\frac{1}{2} || Y - Ax||_{2}^{2}.$$\n",
    "Clearly, using this formulation, we are supposing that the distribution of the noise inside $Y$ is a white Gaussian. We know instead that a Poisson distribution on the measurements $B$ is more realistic, but the function to minimize $\\mathcal{F}_{P}$ obtained considering $B =Poisson ( I_{0} e^{-Ax})$  is very different from the linear least-square problem for Gaussian Noise and it needs particular algorithms to minimized. \n",
    "By considering a quadratic approximation of function $\\mathcal{F}_{P}$  the problem takes the following form:\n",
    "$$ \\min_{x} \\mathcal{F_{W}} : = \\frac{1}{2} || Y - Ax ||_{W}^{2} \\, \\rightarrow \\, \\min_{x} \\frac{1}{2} \\sum_{i} w_{i} (Y-Ax)_{i} $$\n",
    "where $w_{i} = e^{-Y_{i}} = \\frac{B}{I_{0}}$. The main difference between $\\mathcal{F}$ and $\\mathcal{F}_{W}$ is the weight matrix $W$.\n",
    "In this notebook we will see the difference between the solution obtained by minimizing $\\mathcal{F}$ and $\\mathcal{F}_{W}$ for the case of low dose CT, i.e. where the distribution of the noise is very different from a white gaussian, and the level of the noise is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b348b-65a7-4eb4-a11c-5d93f74d0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cil imports\n",
    "from cil.framework import ImageData, ImageGeometry, DataContainer\n",
    "from cil.framework import AcquisitionGeometry, AcquisitionData\n",
    "from cil.optimisation.functions import Function\n",
    "from cil.processors import Slicer, AbsorptionTransmissionConverter, TransmissionAbsorptionConverter\n",
    "\n",
    "from cil.optimisation.functions import LeastSquares, WeightedL2NormSquared, KullbackLeibler, OperatorCompositionFunction, ZeroFunction \n",
    "from cil.optimisation.functions import IndicatorBox, L2NormSquared, TotalVariation, SumFunction, SmoothMixedL21Norm\n",
    "from cil.optimisation.algorithms import CGLS, SIRT, GD, PDHG, FISTA\n",
    "from cil.optimisation.operators import GradientOperator\n",
    "\n",
    "from cil.plugins.astra.operators import ProjectionOperator\n",
    "from cil.plugins.astra.processors import FBP\n",
    "\n",
    "#from cil.version import version\n",
    "#print (version)\n",
    "\n",
    "from cil.plugins import TomoPhantom\n",
    "from cil.utilities.quality_measures import mse, mae, psnr\n",
    "from cil.utilities import dataexample\n",
    "from cil.utilities.display import show_geometry\n",
    "\n",
    "# External imports\n",
    "from myplot import show2D\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import scipy as sp\n",
    "import logging\n",
    "import math\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d2d53-475a-46b6-a1da-bc188d166fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up default colour map for visualisation\n",
    "cmap = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73cbc9-5e57-45da-af90-8eb6ddb9fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the backend for FBP and the ProjectionOperator\n",
    "device = 'gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853e94c-a021-4092-8355-4f898186a43e",
   "metadata": {},
   "source": [
    "In this notebook we will use a classical Shepp-Logan phantom generated with the [TomoPhantom toolbox](https://github.com/dkazanc/TomoPhantom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b9efb-6471-4535-9b2c-6a2fcca5f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of pixels\n",
    "n_pixels = 256\n",
    "\n",
    "# Angles\n",
    "angles = np.linspace(0, 360, 500, endpoint=False, dtype=np.float32)\n",
    "\n",
    "# set-up fan-beam AcquisitionGeometry\n",
    "# distance from source to center of rotation\n",
    "dist_source_center = 6#300.0\n",
    "# distance from center of rotation to detector\n",
    "dist_center_detector = 6# 200.0\n",
    "# physical pixel size\n",
    "pixel_size_h = 2/n_pixels\n",
    "\n",
    "# Setup image geometry\n",
    "ig = ImageGeometry(voxel_num_x=n_pixels, \n",
    "                   voxel_num_y=n_pixels, \n",
    "                   voxel_size_x=2/n_pixels, \n",
    "                   voxel_size_y=2/n_pixels)\n",
    "# calculate geometrical magnification\n",
    "mag = (dist_source_center + dist_center_detector) / dist_source_center\n",
    "\n",
    "ag = AcquisitionGeometry(geom_type='cone',\n",
    "                           dimension='2D',\n",
    "                           angles=angles,\n",
    "                           pixel_num_h=n_pixels,\n",
    "                           pixel_size_h=pixel_size_h*mag,\n",
    "                           dist_source_center=dist_source_center,\n",
    "                           dist_center_detector=dist_center_detector)\n",
    "\n",
    "\n",
    "\n",
    "# Setup image geometry\n",
    "ig = ImageGeometry(voxel_num_x=n_pixels, \n",
    "                   voxel_num_y=n_pixels, \n",
    "                   voxel_size_x=ag.pixel_size_h / mag, \n",
    "                   voxel_size_y=ag.pixel_size_h / mag)\n",
    "show_geometry(ag)\n",
    "phantom = TomoPhantom.get_ImageData(num_model=1, geometry=ig)\n",
    "phantom.array[phantom.array<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4205bf2-f676-448d-8cff-6d776315c472",
   "metadata": {},
   "source": [
    "Next, we create our simulated tomographic data by projecting our noiseless phantom to the acquisition space. \n",
    "The variables $\\texttt{noisy\\_counts}$ and $\\texttt{sino\\_noisy}$ represent $B$ and $Y$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c25dbb-9ca4-43ab-8f18-9cca9867e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create projection operator using Astra-Toolbox.\n",
    "A = ProjectionOperator(ig, ag, device)\n",
    "\n",
    "# Create an acqusition data (numerically)\n",
    "sino = A.direct(phantom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd685b2-b2ab-4565-ad3b-533a5fd0a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incident intensity: lower counts will increase the noise\n",
    "background_counts = 1000 \n",
    "\n",
    "# Convert the simulated absorption sinogram to transmission values using Lambert-Beer. \n",
    "# Use as mean for Poisson data generation.\n",
    "# Convert back to absorption sinogram.\n",
    "counts = background_counts * np.exp(-sino.as_array())  \n",
    "tmp = np.exp(-sino.as_array())\n",
    "noisy_counts = np.random.poisson(counts)\n",
    "nonzero = noisy_counts > 0\n",
    "sino_out = np.zeros_like(sino.as_array())\n",
    "sino_out[nonzero] = -np.log(noisy_counts[nonzero] / background_counts)\n",
    "\n",
    "# allocate sino_noisy and fill with noisy data\n",
    "sino_noisy = ag.allocate()\n",
    "sino_noisy.fill(sino_out)\n",
    "\n",
    "psnr_sino = psnr(sino, sino_noisy, data_range = np.max(sino))\n",
    "\n",
    "# Visualize the true and noisy data\n",
    "show2D([counts, noisy_counts], ['true counts', 'noisy counts'], \\\n",
    "       cmap=cmap, num_cols=2, size=(15,10), origin='upper-left')\n",
    "## Visualize the true and noisy data\n",
    "show2D([sino, sino_noisy], ['true sino', \"noisy sino, psnr = %5.3f\" % (psnr_sino)], \\\n",
    "       cmap=cmap, num_cols=2, size=(15,10), origin='upper-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf977ae-0b78-4e9e-bea0-11cf1f8ec92a",
   "metadata": {},
   "source": [
    "# Reconstructing the noisy data using LS TV and WLS TV  (with FISTA)\n",
    "In addition to the least-square or weighted least square term, we considered a Total Variation Regularizer.\n",
    "So, for the LS-TV problem, we want to minimize the following:\n",
    "$$ ||Y-Ax||_{2}^{2} + \\alpha \\, TV(x) $$\n",
    "while for the WLS-TV problem we minimize:\n",
    "$$ ||Y-Ax||_{W}^{2} + \\alpha \\, TV(x) $$\n",
    "where $\\alpha$ is the regularization parameter that balances the two terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07828d25-846c-4035-b18c-a4a67c305283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the fidelity term\n",
    "LS = LeastSquares(A, sino_noisy)\n",
    "\n",
    "# Definition of the regularization parameter\n",
    "alpha_LS = 1\n",
    "\n",
    "#Initialize quantities\n",
    "x0 = ig.allocate(0.0)\n",
    "\n",
    "# Defining the regularization term with the new alpha\n",
    "alpha1_TV = alpha_LS*TotalVariation()\n",
    "\n",
    "# Setting up FISTA\n",
    "myFISTA_LS_TV = FISTA(f=LS, \n",
    "                g=alpha1_TV, \n",
    "                x_init=x0 ,\n",
    "                max_iteration=1000)\n",
    "# Run FISTA\n",
    "myFISTA_LS_TV.run(1000, verbose=0)\n",
    "recon_ls_tv = myFISTA_LS_TV.solution\n",
    "psnr_ls_tv  = psnr(phantom,recon_ls_tv, data_range = np.max(phantom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911abb38-4bb2-4899-b6f8-1c2b2a2e9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the WLS fidelity term\n",
    "weights = noisy_counts/background_counts\n",
    "c = DataContainer(weights)\n",
    "WLS = LeastSquares(A, sino_noisy, 1,c)\n",
    "\n",
    "# Definition of the regularization parameter\n",
    "alpha_WLS = 1\n",
    "\n",
    "#Initialize quantities\n",
    "x0 = ig.allocate(0.0)\n",
    "\n",
    "# Defining the regularization term with the new alpha\n",
    "alpha2_TV = alpha_WLS*TotalVariation()\n",
    "\n",
    "# Setting up FISTA\n",
    "myFISTA_WLS_TV = FISTA(f=WLS, \n",
    "                g=alpha2_TV, \n",
    "                x_init=x0 ,\n",
    "                max_iteration=1000)\n",
    "# Run FISTA\n",
    "myFISTA_WLS_TV.run(1000, verbose=0)\n",
    "recon_wls_tv = myFISTA_WLS_TV.solution\n",
    "psnr_wls_tv  = psnr(phantom,recon_wls_tv, data_range = np.max(phantom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e32f44-2d0f-4a36-bed2-030d513720c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linenumy = 128  # Line to show in the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(phantom.get_slice(horizontal_y=linenumy).as_array(),':k',label=\"phantom\")\n",
    "plt.plot(recon_ls_tv.get_slice(horizontal_y=linenumy).as_array(),label=\"LS TV\")\n",
    "plt.plot(recon_wls_tv.get_slice(horizontal_y=linenumy).as_array(),label=\"WLS TV\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"Reconstruction line horizontal=%3.0f , I0 = %7.f\" % (linenumy,background_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5206bc-befc-4952-bdc6-4f03b4ade307",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([phantom, recon_ls_tv, recon_wls_tv ], [\"phantom, I0 = %7.0f\" % (background_counts), \"LS TV, alpha=%7.6f, psnr= %5.3f\" % (alpha_LS,psnr_ls_tv),\\\n",
    "    \"WLS TV alpha=%7.6f, psnr= %5.3f\" % (alpha_WLS,psnr_wls_tv)], \\\n",
    "       cmap=cmap, fix_range =(0,1), num_cols=3, size=(15,10), origin='upper-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08d0cc-4a0b-4e38-be06-ac767b84d55c",
   "metadata": {},
   "source": [
    "# Attention: the following code needs a lot of time to run\n",
    "As one can notice from the previous code, the solution strongly depends on the choice of the regularization parameter $\\alpha$, whose best value may be different for the two cases considered. For this reason, we can seach ( a posteriori) the best parameter for each strategy, according to the highest PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29a26c-2b1a-460c-b949-a721b2bd4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of the best regularization parametr using LS TV - FISTA\n",
    "alpha_min = 0.00001\n",
    "alpha_max = 0.001\n",
    "alpha_n   = 50\n",
    "alphas    = np.linspace(alpha_min, alpha_max, alpha_n) \n",
    "\n",
    "# Initialize quantities\n",
    "psnr_ls_tv_alpha = np.zeros_like(alphas)\n",
    "max_psnr = 0\n",
    "\n",
    "# Run the loop over the different values of alpha\n",
    "for i in range(alpha_n):\n",
    "    alpha = alphas[i]\n",
    "    # Defining the regularization term with the new alpha\n",
    "    alphaTV = alpha*TotalVariation()\n",
    "    # Setting up FISTA\n",
    "    myFISTATV = FISTA(f=LS, \n",
    "                  g=alphaTV, \n",
    "                  x_init=x0 ,\n",
    "                  max_iteration=1000)\n",
    "    # Run FISTA\n",
    "    myFISTATV.run(1000, verbose=0)\n",
    "    recon_ls_tv_all_alphas = myFISTATV.solution\n",
    "    psnr_ls_tv_alpha[i] = psnr(phantom,recon_ls_tv_all_alphas, data_range = np.max(phantom))\n",
    "    \n",
    "    # plot the reconstruction \n",
    "    show2D([recon_ls_tv_all_alphas], [\"LS TV alpha=%7.6f, psnr = %7.5f\" % (alpha,psnr_ls_tv_alpha[i])], \\\n",
    "       cmap=cmap,fix_range=(0,1), size=(10,10), origin='upper-left')\n",
    "        \n",
    "    # print the value of alpha and the obtained psnr of the reconstruction\n",
    "    print(\"alpha=%7.6f, psnr= %5.3f\" % (alpha,psnr_ls_tv_alpha[i]))\n",
    "    \n",
    "    # Save the best reconstruction\n",
    "    if psnr_ls_tv_alpha[i]>max_psnr:\n",
    "        max_psnr   = psnr_ls_tv_alpha[i]\n",
    "        best_recon = recon_ls_tv_all_alphas\n",
    "        best_alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdf18e-6bc1-43ee-9ca0-4caa8b5548cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of the best regularization parametr using WLS TV - FISTA\n",
    "alpha_min = 0.00001\n",
    "alpha_max = 0.001\n",
    "alpha_n   = 50\n",
    "alphas    = np.linspace(alpha_min, alpha_max, alpha_n) \n",
    "\n",
    "#Initialize quantities\n",
    "psnr_wls_tv_alpha = np.zeros_like(alphas)\n",
    "w_max_psnr = 0\n",
    "\n",
    "# Run the loop over the different values of alpha\n",
    "for i in range(alpha_n):\n",
    "    alpha = alphas[i]\n",
    "    # Defining the regularization term with the new alpha\n",
    "    alphaTV = alpha*TotalVariation()\n",
    "    # Setting up FISTA\n",
    "    myFISTAWTV = FISTA(f=WLS, \n",
    "                  g=alphaTV, \n",
    "                  x_init=x0 ,\n",
    "                  max_iteration=1000)\n",
    "    # Run FISTA\n",
    "    myFISTAWTV.run(1000, verbose=0)\n",
    "    recon_wls_tv_all_alphas = myFISTAWTV.solution\n",
    "    psnr_wls_tv_alpha[i] = psnr(phantom,recon_wls_tv_all_alphas, data_range = np.max(phantom))\n",
    "\n",
    "    # plot the reconstruction \n",
    "    show2D([recon_wls_tv_all_alphas], [\"WLS TV alpha=%7.6f, psnr = %7.5f\" % (alpha,psnr_wls_tv_alpha[i])], \\\n",
    "       cmap=cmap,fix_range=(0,1), size=(10,10), origin='upper-left')\n",
    "        \n",
    "    # print the value of alpha and the obtained psnr of the reconstruction\n",
    "    print(\"alpha=%7.6f, psnr= %5.3f\" % (alpha,psnr_wls_tv_alpha[i]))\n",
    "    \n",
    "    # Save the best reconstruction\n",
    "    if psnr_wls_tv_alpha[i]>w_max_psnr:\n",
    "        w_max_psnr   = psnr_wls_tv_alpha[i]\n",
    "        w_best_recon = recon_wls_tv_all_alphas\n",
    "        w_best_alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e64a0d-ba0c-4f61-83f6-c51a3ca707f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_wls_tv_fista = w_best_recon\n",
    "psnr_wls_tv_fista  = w_max_psnr\n",
    "alpha_wls_tv_fista = w_best_alpha\n",
    "\n",
    "recon_ls_tv_fista = best_recon\n",
    "psnr_ls_tv_fista  = max_psnr\n",
    "alpha_ls_tv_fista = best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe446a-9186-4503-a13e-6686d9ddc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(phantom.get_slice(horizontal_y=linenumy).as_array(),':k',label=\"phantom\")\n",
    "plt.plot(recon_ls_tv_fista.get_slice(horizontal_y=linenumy).as_array(),label=\"LS TV\")\n",
    "plt.plot(recon_wls_tv_fista.get_slice(horizontal_y=linenumy).as_array(),label=\"WLS TV\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"Reconstruction line horizontal best alphas =%3.0f , I0 = %7.f\" % (linenumy,background_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1612eeb-46fa-4786-bf5d-d54c70bd5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(phantom.get_slice(horizontal_x=linenumy).as_array(),':k',label=\"phantom\")\n",
    "plt.plot(recon_ls_tv_fista.get_slice(horizontal_x=linenumy).as_array(),label=\"LS TV\")\n",
    "plt.plot(recon_wls_tv_fista.get_slice(horizontal_x=linenumy).as_array(),label=\"WLS TV\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"Reconstruction line vertical best alphas =%3.0f , I0 = %7.f\" % (linenumy,background_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72684d5a-3fde-4b09-be54-e70be535b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([phantom, recon_ls_tv_fista,recon_wls_tv_fista ], [\"phantom, I0 = %7.0f\" % (background_counts), \"FBP, psnr= %5.3f\" % (psnr_fbp),\\\n",
    "    \"LS TV FISTA alpha=%7.6f, psnr= %5.3f\" % (alpha_ls_tv_fista,psnr_ls_tv_fista),\\\n",
    "    \"WLS TV FISTA alpha=%7.6f, psnr= %5.3f\" % (alpha_wls_tv_fista,psnr_wls_tv_fista)], \\\n",
    "       cmap=cmap, fix_range =(0,1), num_cols=3, size=(15,10), origin='upper-left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c24aa-97bc-4e83-98d5-3f9df137d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(alphas,psnr_ls_tv_alpha,label=\"LS TV\")\n",
    "plt.plot(alphas,psnr_wls_tv_alpha,label=\"wLS TV\")\n",
    "plt.plot(alpha_ls_tv_fista, psnr_ls_tv_fista, '*r')\n",
    "plt.plot(alpha_wls_tv_fista, psnr_wls_tv_fista, '*r')\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"PSNR for different values of alpha, I0 = %7.f\" % (background_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
